@article{Hayashi2025,
  abstract  = {Metaphor detection is challenging in natural language processing (NLP) because it requires recognizing nuanced semantic shifts beyond literal meaning,...},
  author    = {Takuya Hayashi and Minoru Sasaki},
  doi       = {10.3390/BDCC9090218},
  issn      = {2504-2289},
  issue     = {9},
  journal   = {Big Data and Cognitive Computing 2025, Vol. 9,},
  keywords  = {ChatGPT,generative AI,metaphor detection,transformer},
  month     = {8},
  publisher = {Multidisciplinary Digital Publishing Institute},
  title     = {Applying Additional Auxiliary Context Using Large Language Model for Metaphor Detection},
  volume    = {9},
  url       = {https://www.mdpi.com/2504-2289/9/9/218},
  year      = {2025}
}
@article{Jia2024,
  abstract = {Recently, utilizing large language models (LLMs) for metaphor detection has achieved promising results. However, these methods heavily rely on the capabilities of closed-source LLMs, which come with relatively high inference costs and latency. To address this, we propose a method for metaphor detection by fine-tuning open-source LLMs, effectively reducing inference costs and latency with a single inference step. Furthermore, metaphor detection suffers from a severe data scarcity problem, which hinders effective fine-tuning of LLMs. To tackle this, we introduce Curriculum-style Data Augmentation (CDA). Specifically, before fine-tuning, we evaluate the training data to identify correctly predicted instances for fine-tuning, while incorrectly predicted instances are used as seed data for data augmentation. This approach enables the model to quickly learn simpler knowledge and progressively acquire more complex knowledge, thereby improving performance incrementally. Experimental results demonstrate that our method achieves state-of-the-art performance across all baselines. Additionally, we provide detailed ablation studies to validate the effectiveness of CDA.},
  author   = {Kaidi Jia and Yanxia Wu and Ming Liu and Rongsheng Li},
  month    = {12},
  title    = {Curriculum-style Data Augmentation for LLM-based Metaphor Detection},
  url      = {https://arxiv.org/pdf/2412.02956},
  year     = {2024}
}
@article{Tian2024,
  abstract  = {Metaphor detection is a challenging task in figurative language processing, which aims to distinguish between metaphorical and literal expressions in text. Existing methods tackle metaphor detection via training or fine-tuning discriminative models on labeled data. However, these approaches struggle to explain the underlying reasoning process behind the metaphorical/literal judgment. Recently, large language models (LLMs) have shown promise in language reasoning tasks. Although promising, LLM-based methods for metaphor detection and reasoning are still faced with the challenging issue of bringing the explainable concepts for metaphor reasoning and their linguistic manifestation. To fill this gap, we propose a novel Theory guided Scaffolding Instruction (TSI) framework that instructs an LLM to infer the underlying reasoning process of metaphor detection guided by metaphor theories for the first time. Our work is inspired by a pedagogical strategy called scaffolding instruction, which encourages educators to provide questioning and support as scaffolding so as to assist learners in constructing the understanding of pedagogical goals step by step. We first construct a metaphor knowledge graph grounded in metaphor theory, which serves as the instructional structure to obtain a series of scaffolding questions, directing the LLM to incrementally generate the reasoning process for metaphor understanding through dialogue interactions. During this theory guided instruction process, we explore the LLM’s mastery boundary and provide the relevant knowledge as scaffolding support when the question is beyond the LLM’s capability. Experimental results verify that our method significantly outperforms both the LLM-based reasoning methods and the SOTA methods in metaphor detection, indicating the facilitation of metaphor and instruction theories in guiding LLM-enabled reasoning process.},
  author    = {Yuan Tian and Nan Xu and Wenji Mao},
  doi       = {10.18653/V1/2024.NAACL-LONG.428},
  isbn      = {9798891761148},
  journal   = {Proceedings of the 2024 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL 2024},
  pages     = {7738-7755},
  publisher = {Association for Computational Linguistics (ACL)},
  title     = {A Theory Guided Scaffolding Instruction Framework for LLM-Enabled Metaphor Reasoning},
  volume    = {1},
  url       = {https://aclanthology.org/2024.naacl-long.428/},
  year      = {2024}
}
@article{Ichien2024,
  abstract  = {Despite the exceptional performance of large language models (LLMs) on a wide range of tasks involving natural language processing and reasoning, there has been sharp disagreement as to whether their abilities extend to more creative human abilities. A core example is the interpretation of novel metaphors. Here we assessed the ability of GPT-4, a state-of-the-art large language model, to provide natural-language interpretations of a recent AI benchmark (Fig-QA dataset), novel literary metaphors drawn from Serbian poetry and translated into English, and entire novel English poems. GPT-4 outperformed previous AI models on the Fig-QA dataset. For metaphors drawn from Serbian poetry, human judges–blind to the fact that an AI model was involved–rated metaphor interpretations generated by GPT-4 as superior to those provided by a group of college students. In interpreting reversed metaphors, GPT-4, as well as humans, exhibited signs of sensitivity to the Gricean cooperative principle. In addition, for several novel English poems GPT-4 produced interpretations that were rated as excellent or good by a human literary critic. These results indicate that LLMs such as GPT-4 have acquired an emergent ability to interpret literary metaphors, including those embedded in novel poems.},
  author    = {Nicholas Ichien and Dušan Stamenković and Keith J. Holyoak},
  doi       = {10.1080/10926488.2024.2380348;JOURNAL:JOURNAL:HMET19;WGROUP:STRING:PUBLICATION},
  issn      = {15327868},
  issue     = {4},
  journal   = {Metaphor and Symbol},
  month     = {10},
  pages     = {296-309},
  publisher = {Taylor \& Francis Group LLC Philadelphia},
  title     = {Large Language Model Displays Emergent Ability to Interpret Novel Literary Metaphors},
  volume    = {39},
  url       = {https://www.tandfonline.com/doi/pdf/10.1080/10926488.2024.2380348},
  year      = {2024}
}
@misc{Badran2025,
  abstract = {This paper describes our system developed for SemEval-2025 Task 1, subtask A. This shared subtask focuses on multilingual idiom recognition and the ranking of images based on how well they represent the sense in which a nominal compound is used within a given contex-tual sentence. This study explores the use of a pipeline, where task-specific models are sequentially employed to address each problem step by step. The process involves three key steps: first, identifying whether idioms are in their literal or figurative form; second, transforming them if necessary; and finally, using the final form to rank the input images.},
  author   = {Mohamed Badran and Youssof Nawar and Nagwa El - Makky},
  pages    = {546-550},
  title    = {AlexUNLP-NB at SemEval-2025 Task 1: A Pipeline for Idiom Disambiguation and Visual Representation},
  url      = {https://aclanthology.org/2025.semeval-1.76/},
  year     = {2025}
}
@misc{Gao2025,
  abstract = {Idioms condense complex semantics into fixed phrases, and their meaning is often not directly connected to the literal meaning of their constituent words, making idiom comprehension a test of metaphor competence. Metaphor, as a cognitive process in human beings, has not yet found an effective evaluation method to assess the metaphor competence of LLMs (Large Language Models). In this paper, we propose a method to evaluate the metaphor competence of LLMs for the idiom understanding task: the Consistency Rating of Semantic Transparency (CR-ST). This strategy assesses the difficulty of understanding idioms through two dimensions: overall semantic transparency and constituent semantic transparency, aiming to gauge LLMs' mastery of metaphor competence. Subsequently , we introduce a prompt mechanism-Paraphrase Augmentation Strategy with Self-checking (PASS), based on human language logic, which guides the model to enhance its metaphor competence by explicitly generating idiom paraphrases. We conducted a baseline evaluation of seven LLMs on the CINLID and ChID datasets and analyzed the effectiveness of PASS on different subsets of semantic transparency. The experimental results demonstrate that LLMs can achieve performance comparable to PLMs (Pre-trained Language Models) without additional training, and PASS has a positive effect on the metaphor competence of LLMs.},
  author   = {Hui Gao and Jing Zhang (张京) and Peng Zhang and Chang Yang},
  pages    = {10460-10471},
  title    = {Consistency Rating of Semantic Transparency: an Evaluation Method for Metaphor Competence in Idiom Understanding Tasks},
  url      = {https://aclanthology.org/2025.coling-main.697/},
  year     = {2025}
}
@article{Lai2024,
  abstract  = {Figurative language generation (FLG) is the task of reformulating a given text to include a desired figure of speech, such as a hyperbole, a simile, and several others, while still being faithful to the original context. This is a fundamental, yet challenging task in Natural Language Processing (NLP), which has recently received increased attention due to the promising performance brought by pre-trained language models. Our survey provides a systematic overview of the development of FLG, mostly in English, starting with the description of some common figures of speech, their corresponding generation tasks, and datasets. We then focus on various modelling approaches and assessment strategies, leading us to discussing some challenges in this field, and suggesting some potential directions for future research. To the best of our knowledge, this is the first survey that summarizes the progress of FLG including the most recent development in NLP. We also organize corresponding resources, e.g., article lists and datasets, and make them accessible in an open repository. We hope this survey can help researchers in NLP and related fields to easily track the academic frontier, providing them with a landscape and a roadmap of this area.},
  author    = {Huiyuan Lai and Malvina Nissim},
  doi       = {10.1145/3654795;WGROUP:STRING:ACM},
  issn      = {15577341},
  issue     = {10},
  journal   = {ACM Computing Surveys},
  keywords  = {Figurative language,language generation,systematic review},
  month     = {5},
  publisher = {Association for Computing Machinery},
  title     = {A Survey on Automatic Generation of Figurative Language: From Rule-based Systems to Large Language Models},
  volume    = {56},
  url       = {/doi/pdf/10.1145/3654795?download=true},
  year      = {2024}
}
@article{Pukiene2024,
  abstract  = {Asta Pukiene},
  author    = {Asta Pukiene},
  isbn      = {979-12-80225-70-2},
  journal   = {Conference Proceedings. Innovation in Language Learning 2024},
  keywords  = {Bilingualism,English language teaching,codeswitching,multilingualism,post-colonialism,translanguaging},
  month     = {11},
  publisher = {Pixel International Conferences},
  title     = {AI Vs Human Expertise in Figurative Language Comprehension},
  url       = {https://conference.pixel-online.net/library_scheda.php?id_abs=7014},
  year      = {2024}
}
@article{Liu2022,
  abstract  = {Figurative and metaphorical language are commonplace in discourse, and figurative expressions play an important role in communication and cognition. However, figurative language has been a relatively under-studied area in NLP, and it remains an open question to what extent modern language models can interpret nonliteral phrases. To address this question, we introduce Fig-QA, a Winograd-style nonliteral language understanding task consisting of correctly interpreting paired figurative phrases with divergent meanings. We evaluate the performance of several state-of-the-art language models on this task, and find that although language models achieve performance significantly over chance, they still fall short of human performance, particularly in zero- or few-shot settings. This suggests that further work is needed to improve the nonliteral reasoning capabilities of language models.},
  author    = {Emmy Liu and Chenxuan Cui and Kenneth Zheng and Graham Neubig},
  doi       = {10.18653/v1/2022.naacl-main.330},
  isbn      = {9781955917711},
  journal   = {NAACL 2022 - 2022 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference},
  month     = {4},
  pages     = {4437-4452},
  publisher = {Association for Computational Linguistics (ACL)},
  title     = {Testing the Ability of Language Models to Interpret Figurative Language},
  url       = {https://arxiv.org/pdf/2204.12632},
  year      = {2022}
}
@article{Neidlein2020,
  abstract  = {We conduct a linguistic analysis of recent metaphor recognition systems, all of which are based on language models. We show that their performance, although reaching high F-scores, has considerable gaps from a linguistic perspective. First, they perform substantially worse on unconventional metaphors than on conventional ones. Second, they struggle with handling rarer word types. These two findings together suggest that a large part of the systems’ success is due to optimising the disambiguation of conventionalised, metaphoric word senses for specific words instead of modelling general properties of metaphors. As a positive result, the systems show increasing capabilities to recognise metaphoric readings of unseen words if synonyms or morphological variations of these words have been seen before, leading to enhanced generalisation beyond word sense disambiguation.},
  author    = {Arthur Neidlein and Philipp Wiesenbach and Katja Markert},
  doi       = {10.18653/V1/2020.COLING-MAIN.332},
  isbn      = {9781952148279},
  journal   = {COLING 2020 - 28th International Conference on Computational Linguistics, Proceedings of the Conference},
  pages     = {3722-3736},
  publisher = {Association for Computational Linguistics (ACL)},
  title     = {An analysis of language models for metaphor recognition},
  url       = {https://aclanthology.org/2020.coling-main.332/},
  year      = {2020}
}
@article{Dmitrijev2024,
  abstract  = {Metaphors are figures of speech that connect new concepts with well-known ones and they help scientists look at familiar things in a different way, and thanks to that new discoveries are made. Automated detection of metaphors is a challenging task because words are context-specific and different from their literal definition. The article takes this special set of metaphors as its case study. The authors conducted two experiments to discover if large language models (LLMs) are able to detect them and explain what they mean. It was concluded that the task of metaphor-identification requires comprehensive analysis of word phrases. Besides, LLMs should be trained on datasets containing extralinguistic information about the world in general. The task of explaining metaphors explanation seemed to be less difficult. Two language models managed this task, however, further research is required to improve their nonliteral reasoning capabilities to interpret figurative phrases with different meanings.},
  author    = {Alexander Vladislavovitch Dmitrijev and Elena Sergeevna Krupnova and Anastasia Aleksandrovna Protopopova},
  doi       = {10.1007/978-3-031-76797-5_26/TABLES/1},
  isbn      = {9783031767968},
  issn      = {23673389},
  journal   = {Lecture Notes in Networks and Systems},
  keywords  = {analogies,computational linguistics,large language models,metaphors},
  pages     = {326-341},
  publisher = {Springer Science and Business Media Deutschland GmbH},
  title     = {Metaphors and Analogies in the Context of Large Language Models},
  volume    = {1203 LNNS},
  url       = {https://link.springer.com/chapter/10.1007/978-3-031-76797-5_26},
  year      = {2024}
}
@article{Surez-Figueroa2024,
  abstract  = {The application of the easy-to-read (E2R) methodology is one of the ways to achieve cognitive accessibility and specifically, it is a path that guarantees the right of access to information of people with reading comprehension difficulties and thus improves their daily life. This methodology includes a set of guidelines and recommendations whose goal is to present clear and easily understood documents. Such guidelines are used in the manual processes of (a) adapting existing documents and (b) producing new materials. These processes are very time and human-resource consuming, due to the need of involving E2R experts as well as people with cognitive disabilities. In order to alleviate such manual processes, we are currently investigating the development of methods, based on Artificial Intelligence (AI) techniques, to support the E2R adaptation of documents in a (semi)-automatic fashion. The main goal of this research is to help E2R experts in their daily tasks of (a) assessing a particular document with respect to the E2R guidelines and (b) transforming such a document according to the E2R methodology. In this paper we present our initial efforts toward the development of an AI-based application for supporting the E2R adaptation of documents. These efforts are the elicitation of E2R needs and informal requirements and the design of an application called FACILE.},
  author    = {Mari Carmen Suárez-Figueroa and Isam Diab and Edna Ruckhaus and Isabel Cano},
  doi       = {10.1007/S10209-022-00946-Z;JOURNAL:JOURNAL:UAIS;WGROUP:STRING:ACM},
  issn      = {16155297},
  issue     = {1},
  journal   = {Universal Access in the Information Society},
  keywords  = {Artificial intelligence,Cognitive accessibility,Easy-to-read methodology},
  month     = {3},
  pages     = {365-377},
  publisher = {Springer Science and Business Media Deutschland GmbH},
  title     = {First steps in the development of a support application for easy-to-read adaptation},
  volume    = {23},
  url       = {https://dl.acm.org/doi/10.1007/s10209-022-00946-z},
  year      = {2024}
}
@article{Surez-Figueroa2023,
  abstract  = {The Easy-to-Read (E2R) Methodology was created to improve the daily life of people with cognitive disabilities. This methodology aims to present clear and easily understood documents. The E2R Methodology includes, among others, a set of guidelines related to the writing of texts. Some of these guidelines focus on morphological features that may cause difficulties in reading comprehension. Examples of those guidelines are: (a) to avoid the use of adverbs ending in -mente (-ly in English), and (b) to avoid the use of superlative forms. Both linguistic structures are quite long, which is also related to another E2R guideline (“The use of long words should be avoided”). Currently, E2R guidelines are applied manually to create easy-to-read text materials. To help in such a manual process, our research line is focused on applying the E2R Methodology in Spanish texts in a (semi)-automatic fashion. Specifically, in this paper we present (a) the inclusive design approach for the development of E2R adaptation methods for avoiding adverbs ending in -mente and superlative forms, (b) the initial methods for adapting those morphological features to an E2R version, and (c) a preliminary user-based evaluation of the implementation of those methods.},
  author    = {Mari Carmen Suárez-Figueroa and Isam Diab and Álvaro González and Jesica Rivero-Espinosa},
  doi       = {10.1007/978-3-031-42280-5_12/TABLES/4},
  isbn      = {9783031422799},
  issn      = {16113349},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords  = {Artificial Intelligence,Cognitive Accessibility,Easy-to-Read Methodology},
  pages     = {176-198},
  publisher = {Springer Science and Business Media Deutschland GmbH},
  title     = {Towards an Automatic Easy-to-Read Adaptation of Morphological Features in Spanish Texts},
  volume    = {14142 LNCS},
  url       = {https://link.springer.com/chapter/10.1007/978-3-031-42280-5_12},
  year      = {2023}
}
@article{Diab2024,
  abstract  = {People with cognitive disabilities have the right to actively participate in various aspects of society, including culture, on an equal basis with others. Related with this social need, a methodology called Easy-to-Read (E2R) was created to improve cognitive accessibility. This methodology provides a set of guidelines and recommendations to present clear and easily understood contents to different sectors of the population that include people with cognitive disabilities. One of these guidelines refers to structuring dialogues in a theatrical style, i.e. placing the name of each character ahead of their intervention, to make it explicit who is the speaker of each intervention and thus avoid having to infer this information. Since the E2R methodology is currently applied in a manual fashion, we have developed an initial method for automatically adapting dialogues in narrative texts in Spanish to theatrical style. This method is based on (a) Artificial Intelligence (AI) methods and techniques and (b) the E2R guidelines. We have implemented such a method as a proof of concept and we have validated its functionality trough a user-based study involving people with cognitive disabilities.},
  author    = {Isam Diab and Mari Carmen Suárez-Figueroa and Roberto Peris},
  doi       = {10.1007/978-3-031-62849-8_26/TABLES/1},
  isbn      = {9783031628481},
  issn      = {16113349},
  journal   = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
  keywords  = {Cognitive Accessibility,Dialogues,Easy-to-Read Methodology},
  pages     = {208-216},
  publisher = {Springer Science and Business Media Deutschland GmbH},
  title     = {Towards an Automatic Easy-to-Read Adaptation of Dialogues in Narrative Texts in Spanish},
  volume    = {14751 LNCS},
  url       = {https://link.springer.com/chapter/10.1007/978-3-031-62849-8_26},
  year      = {2024}
}
